{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start, we install Rasterio, a Python module for interacting with gridded spatial data\n",
    "!pip install rasterio\n",
    "!pip install xarray\n",
    "!pip install dask\n",
    "!pip install dask-image\n",
    "!pip install graphviz\n",
    "!pip install scikit-image\n",
    "!python -m pip install \"dask[distributed]\" --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask_image.imread\n",
    "import dask_image.ndfilters\n",
    "import dask_image.ndmeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll also use matplotlib to display image results in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the example data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use some example image data from the scikit-image library in this tutorial. These images are very small, but will allow us to demonstrate the functionality of dask-image. <br>\n",
    "Let's download and save a public domain image of the astronaut Eileen Collins to a temporary directory. This image was originally downloaded from the NASA Great Images database https://flic.kr/p/r9qvLn, but we'll access it with scikit-image's data.astronaut() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from skimage import data, io\n",
    "\n",
    "output_filename = os.path.join(\"temp\", \"astronaut.png\")\n",
    "io.imsave(output_filename, data.astronaut())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really large datasets often can't fit all of the data into a single file, so we'll chop this image into four parts and save the image tiles to a second temporary directory. This will give you a better idea of how you can use dask-image on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir temp-tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imsave(os.path.join(\"temp-tiles\", \"image-00.png\"), data.astronaut()[:256, :256, :])  # top left\n",
    "io.imsave(os.path.join(\"temp-tiles\", \"image-01.png\"), data.astronaut()[:256, 256:, :])  # top right\n",
    "io.imsave(os.path.join(\"temp-tiles\", \"image-10.png\"), data.astronaut()[256:, :256, :])  # bottom left\n",
    "io.imsave(os.path.join(\"temp-tiles\", \"image-11.png\"), data.astronaut()[256:, 256:, :])  # bottom right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have some data saved, let's practise reading in files with dask-image and processing our images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Reading in image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a single image. <br>\n",
    "Let's load a public domain image of the astronaut Eileen Collins with dask-image imread(). This image was originally downloaded from the NASA Great Images database https://flic.kr/p/r9qvLn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename = os.path.join(\"temp\", \"astronaut.png\")\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut = dask_image.imread.imread(filename)\n",
    "print(astronaut)\n",
    "plt.imshow(astronaut[0, ...])  # display the first (and only) frame of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has created a dask array with shape=(1, 512, 512, 3). This means it contains one image frame with 512 rows, 512 columns, and 3 color channels.\n",
    "Since the image is relatively small, it fits entirely within one dask-image chunk, with chunksize=(1, 512, 512, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading multiple images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, you may have multiple images stored on disk, for example: image_00.png, image_01.png, ... image_NN.png. These can be read into a dask array as multiple image frames. <br>\n",
    "\n",
    "Here we have the astronaut image split into four non-overlapping tiles: <br>\n",
    "\n",
    "- image_00.png = top left image (index 0,0)\n",
    "- image_01.png = top right image (index 0,1)\n",
    "- image_10.png = bottom left image (index 1,0)\n",
    "- image_11.png = bottom right image (index 1,1)\n",
    "\n",
    "This filename pattern can be matched with regex: image-*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls temp-tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename_pattern = os.path.join(\"temp-tiles\", \"image-*.png\")\n",
    "tiled_astronaut_images = dask_image.imread.imread(filename_pattern)\n",
    "print(tiled_astronaut_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has created a dask array with shape=(4, 256, 256, 3). This means it contains four image frames; each with 256 rows, 256 columns, and 3 color channels.\n",
    "There are four chunks in this particular case. Each image frame here is a separate chunk with chunksize=(1, 256, 256, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2)\n",
    "ax[0, 0].imshow(tiled_astronaut_images[0])\n",
    "ax[0, 1].imshow(tiled_astronaut_images[1])\n",
    "ax[1, 0].imshow(tiled_astronaut_images[2])\n",
    "ax[1, 1].imshow(tiled_astronaut_images[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying your own custom function to images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you'll want to do some image processing, and apply a function to your images. <br>\n",
    "\n",
    "We'll use a very simple example: converting an RGB image to grayscale. But you can also use this method to apply arbittrary functions to dask images. To convert our image to grayscale, we'll use the equation to calculate luminance: <br>\n",
    "\n",
    "> - Y = 0.2125 R + 0.7154 G + 0.0721 B\n",
    "\n",
    "We'll write the function for this equation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(rgb):\n",
    "    result = ...  # TODO\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function to the astronaut image we read in as a single file and visualize the computation graph.\n",
    "\n",
    "(Visualizing the computation graph isn't necessary most of the time but it's helpful to know what dask is doing under the hood, and it can also be very useful for debugging problems.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_image_result = grayscale(astronaut)\n",
    "print(single_image_result)\n",
    "single_image_result.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that there are no longer three color channels in the shape of the result, and that the output image is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original image dimensions: \", astronaut.shape)\n",
    "print(\"Processed image dimensions:\", single_image_result.shape)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2)\n",
    "ax0.imshow(astronaut[0, ...])  # display the first (and only) frame of the image\n",
    "ax1.imshow(single_image_result[0, ...], cmap=\"gray\")  # display the first (and only) frame of the image\n",
    "\n",
    "# Subplot headings\n",
    "ax0.set_title(\"Original image\")\n",
    "ax1.set_title(\"Processed image\")\n",
    "\n",
    "# Don't display axes\n",
    "ax0.axis(\"off\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# Display images\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embarrassingly parallel problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is identical to apply a function to multiple images or dask chunks. This is an example of an embarrassingly parallel problem, and we see that dask automatically creates a computation graph for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ...  ## TODO ON TILEDS ASTRONAUT IMAGES\n",
    "print(result)\n",
    "result.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\n",
    "ax0.imshow(result[0, ...], cmap=\"gray\")\n",
    "ax1.imshow(result[1, ...], cmap=\"gray\")\n",
    "ax2.imshow(result[2, ...], cmap=\"gray\")\n",
    "ax3.imshow(result[3, ...], cmap=\"gray\")\n",
    "\n",
    "# Subplot headings\n",
    "ax0.set_title(\"First chunk\")\n",
    "ax1.set_title(\"Second chunk\")\n",
    "ax2.set_title(\"Thurd chunk\")\n",
    "ax3.set_title(\"Fourth chunk\")\n",
    "\n",
    "# Don't display axes\n",
    "ax0.axis(\"off\")\n",
    "ax1.axis(\"off\")\n",
    "ax2.axis(\"off\")\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "# Display images\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining partial images together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, Things are looking pretty good! But how can we join these image chunks together?\n",
    "\n",
    "So far, we haven't needed any information from neighboring pixels to do our calculations. But there are lots of functions (like those in dask-image ndfilters) that do need this for accurate results. You could end up with unwanted edge effects if you don't tell dask how your images should be joined.\n",
    "\n",
    "Dask has several ways to join chunks together: Stack, Concatenate, and Block.\n",
    "\n",
    "Block is very versatile, so we'll use that in this next example. You simply pass in a list (or list of lists) to tell dask the spatial relationship between image chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[result[0, ...], result[1, ...]], [result[2, ...], result[3, ...]]]\n",
    "combined_image = ...  ## TODO\n",
    "print(combined_image.shape)\n",
    "plt.imshow(combined_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A segmentation analysis pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll walk through a simple image segmentation and analysis pipeline with three steps:\n",
    "\n",
    "1. Filtering\n",
    "2. Segmenting\n",
    "3. Analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "Most analysis pipelines require some degree of image preprocessing. dask-image has a number of inbuilt filters available via dask-image ndfilters.\n",
    "\n",
    "Commonly a guassian filter may used to smooth the image before segmentation. This causes some loss of sharpness in the image, but can improve segmentation quality for methods that rely on image thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_image = ...  ## TODO apply gaussian filter from dask_image.ndfilters with unit variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a small amount of blur in the smoothed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2)\n",
    "ax0.imshow(smoothed_image, cmap=\"gray\")\n",
    "ax1.imshow(smoothed_image - combined_image, cmap=\"gray\")\n",
    "\n",
    "# Subplot headings\n",
    "ax0.set_title(\"Smoothed image\")\n",
    "ax1.set_title(\"Difference from original\")\n",
    "\n",
    "# Don't display axes\n",
    "ax0.axis(\"off\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# Display images\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the gaussian filter uses information from neighbouring pixels, the computational graph looks more complicated than the ones we looked at earlier. This is no longer embarrassingly parallel. Where possible dask keeps the computations for each of the four image chunks separate, but must combine information from different chunks near the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_image.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting\n",
    "After the image preprocessing, we segment regions of interest from the data. We'll use a simple arbitrary threshold as the cutoff, at 75% of the maximum intensity of the smoothed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 0.75 * da.max(smoothed_image).compute()\n",
    "print(threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_image = smoothed_image > threshold_value\n",
    "plt.imshow(threshold_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we label each region of connected pixels above the threshold value. For this we use the label function from dask-image ndmeasure. This will return both the label image, and the number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_image, num_labels = ...  ## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of labels:\", int(num_labels))  # You have to find 78 labels\n",
    "plt.imshow(label_image, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and manipulating tiled GeoTIFF datasets\n",
    "\n",
    "This notebook shows how to perform simple calculations with a GeoTIFF dataset using XArray and Dask. We load and rescale a Landsat 8 image and compute NDVI (Normalized difference vegetation index). This can be used to distinguish green vegetation from areas of bare land or water.\n",
    "\n",
    "We'll use an image of the Denver, USA area taken in July 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RGB image](https://landsat-pds.s3.amazonaws.com/c1/L8/033/033/LC08_L1TP_033033_20180706_20180717_01_T1/LC08_L1TP_033033_20180706_20180717_01_T1_thumb_small.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "First, we download the dataset. We are using an image from the cloud-hosted [Landsat 8 public dataset](https://landsatonaws.com/) and each band is available as a separate GeoTIFF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import requests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_filename = \"https://landsat-pds.s3.amazonaws.com/c1/L8/033/033/LC08_L1TP_033033_20180706_20180717_01_T1/LC08_L1TP_033033_20180706_20180717_01_T1_B5.TIF\"\n",
    "red_filename = \"https://landsat-pds.s3.amazonaws.com/c1/L8/033/033/LC08_L1TP_033033_20180706_20180717_01_T1/LC08_L1TP_033033_20180706_20180717_01_T1_B4.TIF\"\n",
    "mtl_filename = \"https://landsat-pds.s3.amazonaws.com/c1/L8/033/033/LC08_L1TP_033033_20180706_20180717_01_T1/LC08_L1TP_033033_20180706_20180717_01_T1_MTL.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(in_filename, out_filename):\n",
    "    if not os.path.exists(out_filename):\n",
    "        print(\"Downloading\", in_filename)\n",
    "        response = requests.get(in_filename)\n",
    "        with open(out_filename, \"wb\") as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(nir_filename, \"nir.tif\")\n",
    "download_file(red_filename, \"red.tif\")\n",
    "download_file(mtl_filename, \"meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check image metadata\n",
    "\n",
    "Let's see if the image is tiled so we can select a chunk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rasterio.open(\"red.tif\")\n",
    "print(img.is_tiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.block_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image has separate blocks for each band with block size 512 x 512. \n",
    "\n",
    "## Create XArray datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "red = xr.open_rasterio(\"red.tif\", chunks={\"band\": 1, \"x\": 1024, \"y\": 1024})\n",
    "nir = xr.open_rasterio(\"nir.tif\", chunks={\"band\": 1, \"x\": 1024, \"y\": 1024})\n",
    "nir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset's data is a Dask array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.variable.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: create a Dask client\n",
    "\n",
    "You can start a Dask client to monitor execution with the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(processes=False)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale bands using Landsat metadata\n",
    "\n",
    "The Landsat Level 1 images are delivered in a quantized format. This has to be [converted to top-of-atmosphere reflectance](https://landsat.usgs.gov/using-usgs-landsat-8-product) using the provided metadata.\n",
    "\n",
    "First we define convenience functions to load the rescaling factors and transform a dataset. The red band is band 4 and near infrared is band 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scale_factors(filename, band_number):\n",
    "    with open(filename) as f:\n",
    "        metadata = json.load(f)\n",
    "    M_p = metadata[\"L1_METADATA_FILE\"][\"RADIOMETRIC_RESCALING\"][\"REFLECTANCE_MULT_BAND_{}\".format(band_number)]\n",
    "    A_p = metadata[\"L1_METADATA_FILE\"][\"RADIOMETRIC_RESCALING\"][\"REFLECTANCE_ADD_BAND_{}\".format(band_number)]\n",
    "    return M_p, A_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reflectance(ds, band_number, metafile=\"meta.json\"):\n",
    "    M_p, A_p = load_scale_factors(metafile, band_number)\n",
    "    toa = M_p * ds + A_p\n",
    "    return toa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_toa = ...  ##TODO calculate refletance for red band\n",
    "nir_toa = ...  ##TODO calculate refletance for nir band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the transformation is composed of arithmetic operations, execution is delayed and the operations are parallelized automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(red_toa.variable.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting image has floating point data with magnitudes appropriate to reflectance. This can be checked by computing the range of values in an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_max, red_min, red_mean = dask.compute(\n",
    "    red_toa.max(dim=[\"x\", \"y\"]), red_toa.min(dim=[\"x\", \"y\"]), red_toa.mean(dim=[\"x\", \"y\"])\n",
    ")\n",
    "print(red_max.item())\n",
    "print(red_min.item())\n",
    "print(red_mean.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and display NDVI\n",
    "\n",
    "Now that we have the image as reflectance values, we are ready to compute NDVI.\n",
    "\n",
    "$$\n",
    "NDVI = \\frac{NIR - Red}{NIR + Red}\n",
    "$$\n",
    "\n",
    "This highlights areas of healthy vegetation with high NDVI values, which appear as green in the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = ...  ## TODO Compute NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi2d = ...  ## Remove one dimension of ndvi (tensor) for 2D plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "im = ndvi2d.compute().plot.imshow(cmap=\"BrBG\", vmin=-0.5, vmax=1)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the International Space Station with Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use two APIs: Google Maps Geocoder & Open Notify API for ISS location. <br>\n",
    "We will use them to track ISS location and next transit time with respect to a list of cities. To create our charts and parallelise data intelligently, we will use Dask, specifically Dask Delayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from math import radians\n",
    "from operator import itemgetter\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from dask import delayed\n",
    "from sklearn.neighbors import DistanceMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude and longitude pairs from a list of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_long(address):\n",
    "    resp = requests.get(\n",
    "        \"https://eu1.locationiq.org/v1/search.php\", params={\"key\": \"92e7ba84cf3465\", \"q\": address, \"format\": \"json\"}\n",
    "    )\n",
    "    if resp.status_code != 200:\n",
    "        print(\"There was a problem with your request!\")\n",
    "        print(resp.content)\n",
    "        return\n",
    "    data = resp.json()[0]\n",
    "    return {\n",
    "        \"name\": data.get(\"display_name\"),\n",
    "        \"lat\": float(data.get(\"lat\")),\n",
    "        \"long\": float(data.get(\"lon\")),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lat_long(\"Berlin, Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = []\n",
    "for city in [\n",
    "    \"Seattle, Washington\",\n",
    "    \"Miami, Florida\",\n",
    "    \"Berlin, Germany\",\n",
    "    \"Singapore\",\n",
    "    \"Wellington, New Zealand\",\n",
    "    \"Beirut, Lebanon\",\n",
    "    \"Beijing, China\",\n",
    "    \"Nairobi, Kenya\",\n",
    "    \"Cape Town, South Africa\",\n",
    "    \"Buenos Aires, Argentina\",\n",
    "]:\n",
    "    locations.append(get_lat_long(city))\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve ISS data and determine transit times of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spaceship_location():\n",
    "    resp = requests.get(\"http://api.open-notify.org/iss-now.json\")\n",
    "    location = resp.json()[\"iss_position\"]\n",
    "    return {\"lat\": float(location.get(\"latitude\")), \"long\": float(location.get(\"longitude\"))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def great_circle_dist(lon1, lat1, lon2, lat2):\n",
    "    dist = DistanceMetric.get_metric(\"haversine\")\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    X = [[lat1, lon1], [lat2, lon2]]\n",
    "    kms = 6367\n",
    "    return (kms * dist.pairwise(X)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iss_dist_from_loc(issloc, loc):\n",
    "    distance = great_circle_dist(issloc.get(\"long\"), issloc.get(\"lat\"), loc.get(\"long\"), loc.get(\"lat\"))\n",
    "    logging.info(\"ISS is ~%dkm from %s\", int(distance), loc.get(\"name\"))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iss_pass_near_loc(loc):\n",
    "    resp = requests.get(\n",
    "        \"http://api.open-notify.org/iss-pass.json\", params={\"lat\": loc.get(\"lat\"), \"lon\": loc.get(\"long\")}\n",
    "    )\n",
    "    data = resp.json().get(\"response\")[0]\n",
    "    td = datetime.fromtimestamp(data.get(\"risetime\")) - datetime.now()\n",
    "    m, s = divmod(int(td.total_seconds()), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    logging.info(\"ISS will pass near %s in %02d:%02d:%02d\", loc.get(\"name\"), h, m, s)\n",
    "    return td.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss_dist_from_loc(get_spaceship_location(), locations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss_pass_near_loc(locations[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a delayed pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO find the closest city\n",
    "## hint: loop on locations -> compute get_spaceship_location and the iss_dist_from_loc\n",
    "## To transform a function into a dask delayed function, use delayed. For instance, delayed(get_spaceship_location)()\n",
    "## Visualise the pipeline to see what happens\n",
    "## Don't forget the compute() to get a value and find the closest city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "Here are some interesting examples you can take a look at to get a better feel on how to use Dask in your future career\n",
    "\n",
    "**Stackstac examples we saw during the class**\n",
    "\n",
    "https://stackstac.readthedocs.io/en/latest/examples/show.html\n",
    "\n",
    "**Interactive visualization and near real-time analysis - Draga Doncila Pop | Dask Summit 2021**\n",
    "\n",
    "https://www.youtube.com/watch?v=10Ws59NGDaE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-10.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m87"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
